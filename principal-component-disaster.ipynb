{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal component disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Creator: Magnus Struckmann*\n",
    "## Table of contents\n",
    "\n",
    "- Notebook description\n",
    "- Create data sets\n",
    "- Visualize blob data\n",
    "- Visualize elbow plots of explained variance from PCA\n",
    "- Visualize PCA transformation fitted on training data\n",
    "- Visualize PCA transformation applied on testing data\n",
    "- Visualize decision boundaries and training data\n",
    "- Visualize decision boundaries and test data\n",
    "- Visualize surface probability and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook description\n",
    "\n",
    "To analyze the consequences of changing the distance between blob data centers 30 different data sets are created.\n",
    "Only the distance between the centers of the Gaussian distributed blobs is changed while the standard deviation and the random initialization parameter are kept constant.\n",
    "\n",
    "Each data set contains 1000 data points that are equally distributed among the four data classes.\n",
    "A principal component analysis is performed on each data set and a logistic regression classifier fitted to its output.\n",
    "All results are saved to the *df_collection* dictionary.\n",
    "\n",
    "The different data sets, PCA results and logistic regression predicitions are visualized with Plotly to conclude on the consequences of changing the distance between blob data centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection = []\n",
    "for step in np.arange(0, 3, 0.1): # Step size for distance between blob centers\n",
    "    \n",
    "    # Create blob data\n",
    "    distance = step\n",
    "    centers = [\n",
    "        [distance,-distance,-distance],\n",
    "        [-distance,distance,-distance],\n",
    "        [-distance,distance,distance],\n",
    "        [distance,-distance,distance]]\n",
    "    \n",
    "    X, y = datasets.make_blobs(n_samples=1000,\n",
    "                               random_state=42,\n",
    "                               n_features=3,\n",
    "                               cluster_std=1,\n",
    "                               centers=centers)\n",
    "    \n",
    "    data = np.column_stack((X, y))\n",
    "    df = pd.DataFrame(data, columns = ['Feature 1','Feature 2','Feature 3','Cluster'])\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)\n",
    "    \n",
    "    # Standardize data\n",
    "    sc = StandardScaler()\n",
    "    X_train_std = sc.fit_transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)  \n",
    "    \n",
    "    # Principal component analysis\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(X_train_std)\n",
    "    pca_var = pca.explained_variance_ratio_\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_X_train = pca.fit_transform(X_train_std)\n",
    "    pca_X_test = pca.transform(X_test_std)\n",
    "    pca_X = np.append(pca_X_train, pca_X_test, axis=0)\n",
    "    \n",
    "    # Fit logistic regression model\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(pca_X_train, y_train)\n",
    "\n",
    "    # Make predictions over complete PCA feature space (min and max of training and test data)\n",
    "    h = .02  # step size in the mesh\n",
    "    x_min, x_max = pca_X[:, 0].min() - 1, pca_X[:, 0].max() + 1\n",
    "    y_min, y_max = pca_X[:, 1].min() - 1, pca_X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    y_ = np.arange(y_min, y_max, h)\n",
    "    Z_class_prediction = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z_class_prediction = Z_class_prediction.reshape(xx.shape)\n",
    "    Z_probability_label1 = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,0] # probability for class 1\n",
    "    Z_probability_label1 = Z_probability_label1.reshape(xx.shape)\n",
    "    \n",
    "    step_dict = dict(distance=round(step,1),\n",
    "                     data=df,\n",
    "                     pca_var=pca_var,\n",
    "                     pca_X_train=pca_X_train,\n",
    "                     pca_X_test=pca_X_test,\n",
    "                     y_train=y_train,\n",
    "                     y_test=y_test,\n",
    "                     xx_meshgrid=xx,\n",
    "                     y_meshgrid=y_,\n",
    "                     Z_class_prediction=Z_class_prediction,\n",
    "                     Z_probability_label1=Z_probability_label1)\n",
    "    \n",
    "    df_collection.append(step_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize blob data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces, one for each slider step\n",
    "for step_dict in df_collection:\n",
    "    df = step_dict['data']\n",
    "\n",
    "    trace = go.Scatter3d(x=df['Feature 1'], y=df['Feature 2'], z=df['Feature 3'],\n",
    "                          mode='markers',\n",
    "                          marker=dict(size=12,color=df['Cluster']),\n",
    "                          visible=False)\n",
    "\n",
    "    fig.add_trace(trace)\n",
    "        \n",
    "# Make 10th trace visible\n",
    "fig.data[10].visible = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and add slider\n",
    "def create_sliders(df_collection):\n",
    "    steps = []\n",
    "    for i,step_dict in enumerate(df_collection):\n",
    "        step = dict(\n",
    "            method=\"restyle\",\n",
    "            args=[\"visible\", [False] * len(df_collection)],\n",
    "            label=str(step_dict['distance']),\n",
    "        )\n",
    "        step[\"args\"][1][i] = True  # Toggle i'th trace to \"visible\"\n",
    "        steps.append(step)\n",
    "\n",
    "    sliders = [dict(\n",
    "        active=10,\n",
    "        currentvalue={\"prefix\": \"Distance: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=steps\n",
    "    )]\n",
    "    return sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot\n",
    "fig.update_layout(\n",
    "    sliders=create_sliders(df_collection),\n",
    "    scene = dict(xaxis_title='Feature 1',\n",
    "                 yaxis_title='Feature 2',\n",
    "                 zaxis_title='Feature 3'),\n",
    "                 margin=dict(r=20, b=10, l=10, t=10))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize elbow plots of explained variance from PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces, one for each slider step\n",
    "for step_dict in df_collection:\n",
    "    pca_var = step_dict['pca_var']\n",
    "    \n",
    "    components=['Component 1', 'Component 2', 'Component 3']\n",
    "    trace = go.Bar(x=components, \n",
    "                   y=pca_var,\n",
    "                   visible=False)\n",
    "    \n",
    "    fig.add_trace(trace)\n",
    "\n",
    "# Make 10th trace visible\n",
    "fig.data[10].visible = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot\n",
    "fig.update_layout(\n",
    "    sliders=create_sliders(df_collection),\n",
    "    yaxis=dict(title='Explained variance ratio'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize PCA transformation fitted on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces, one for each slider step\n",
    "for step_dict in df_collection:\n",
    "    pca_X_train = step_dict['pca_X_train']\n",
    "    y_train = step_dict['y_train']\n",
    "\n",
    "    trace = go.Scatter(x=pca_X_train[:,0], y=pca_X_train[:,1],\n",
    "                       mode='markers',\n",
    "                       marker=dict(size=12,color=y_train),\n",
    "                       visible=False)\n",
    "\n",
    "    fig.add_trace(trace)\n",
    "        \n",
    "# Make 10th trace visible\n",
    "fig.data[10].visible = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot\n",
    "fig.update_layout(\n",
    "    sliders=create_sliders(df_collection),\n",
    "    xaxis=dict(title='Component 1'),\n",
    "    yaxis=dict(title='Component 2'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize PCA transformation applied on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces, one for each slider step\n",
    "for step_dict in df_collection:\n",
    "    pca_X_test = step_dict['pca_X_test']\n",
    "    y_test = step_dict['y_test']\n",
    "\n",
    "    trace = go.Scatter(x=pca_X_test[:,0], y=pca_X_test[:,1],\n",
    "                       mode='markers',\n",
    "                       marker=dict(size=12,color=y_test),\n",
    "                       visible=False)\n",
    "\n",
    "    fig.add_trace(trace)\n",
    "        \n",
    "# Make 10th trace visible\n",
    "fig.data[10].visible = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot\n",
    "fig.update_layout(\n",
    "    sliders=create_sliders(df_collection),\n",
    "    xaxis=dict(title='Component 1'),\n",
    "    yaxis=dict(title='Component 2'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize decision boundaries and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces, one for each slider step\n",
    "for step_dict in df_collection:\n",
    "    X = step_dict['pca_X_train']\n",
    "    y = step_dict['y_train']\n",
    "    xx = step_dict['xx_meshgrid']    \n",
    "    y_ = step_dict['y_meshgrid']\n",
    "    Z = step_dict['Z_class_prediction']\n",
    "    \n",
    "    trace = go.Heatmap(x=xx[0], y=y_, z=Z,\n",
    "                       showscale=True,\n",
    "                       visible=False)\n",
    "    \n",
    "    fig.add_trace(trace)\n",
    "\n",
    "    trace = go.Scatter(x=X[:, 0], y=X[:, 1], \n",
    "                       mode='markers',\n",
    "                       showlegend=False,\n",
    "                       marker=dict(size=10,color=y,line=dict(color='black', width=1)),\n",
    "                       visible=False)\n",
    "\n",
    "    fig.add_trace(trace)\n",
    "        \n",
    "# Make 10th trace visible\n",
    "fig.data[19].visible = True # (because we add two traces per plot we need to multiply by two and make both visible)\n",
    "fig.data[20].visible = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and add slider (two traces per plot)\n",
    "def create_sliders_2traces(df_collection):\n",
    "    steps = []\n",
    "    for i,step_dict in enumerate(df_collection):\n",
    "        step = dict(\n",
    "            method=\"restyle\",\n",
    "            args=[\"visible\", [False] * len(df_collection)*2],\n",
    "            label=str(step_dict['distance']),\n",
    "        )\n",
    "        step[\"args\"][1][i*2] = True  # Toggle i'th trace to \"visible\"\n",
    "        step[\"args\"][1][i*2+1] = True\n",
    "        steps.append(step)\n",
    "\n",
    "    sliders = [dict(\n",
    "        active=10,\n",
    "        currentvalue={\"prefix\": \"Distance: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=steps\n",
    "    )]\n",
    "    return sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot\n",
    "fig.update_layout(   \n",
    "    sliders=create_sliders_2traces(df_collection),\n",
    "    xaxis=dict(title='Component 1'),\n",
    "    yaxis=dict(title='Component 2'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize decision boundaries and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces, one for each slider step\n",
    "for step_dict in df_collection:\n",
    "    X = step_dict['pca_X_test']\n",
    "    y = step_dict['y_test']\n",
    "    xx = step_dict['xx_meshgrid']    \n",
    "    y_ = step_dict['y_meshgrid']\n",
    "    Z = step_dict['Z_class_prediction']\n",
    "    \n",
    "    trace = go.Heatmap(x=xx[0], y=y_, z=Z,\n",
    "                       showscale=True,\n",
    "                       visible=False)\n",
    "    \n",
    "    fig.add_trace(trace)\n",
    "\n",
    "    trace = go.Scatter(x=X[:, 0], y=X[:, 1], \n",
    "                       mode='markers',\n",
    "                       showlegend=False,\n",
    "                       marker=dict(size=10,color=y,line=dict(color='black', width=1)),\n",
    "                       visible=False)\n",
    "\n",
    "    fig.add_trace(trace)\n",
    "        \n",
    "# Make 10th trace visible\n",
    "fig.data[19].visible = True # (because we add two traces per plot we need to multiply by two and make both visible)\n",
    "fig.data[20].visible = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot\n",
    "fig.update_layout(   \n",
    "    sliders=create_sliders_2traces(df_collection),\n",
    "    xaxis=dict(title='Component 1'),\n",
    "    yaxis=dict(title='Component 2'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize surface probability and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add traces, one for each slider step\n",
    "for step_dict in df_collection:\n",
    "    X = step_dict['pca_X_test']\n",
    "    y = step_dict['y_test']\n",
    "    xx = step_dict['xx_meshgrid']    \n",
    "    y_ = step_dict['y_meshgrid']\n",
    "    Z = step_dict['Z_probability_label1']\n",
    "    \n",
    "    trace = go.Heatmap(x=xx[0], y=y_, z=Z,\n",
    "                       showscale=True,\n",
    "                       visible=False)\n",
    "    \n",
    "    fig.add_trace(trace)\n",
    "\n",
    "    trace = go.Scatter(x=X[:, 0], y=X[:, 1], \n",
    "                       mode='markers',\n",
    "                       showlegend=False,\n",
    "                       marker=dict(size=10,color=y,line=dict(color='black', width=1)),\n",
    "                       visible=False)\n",
    "\n",
    "    fig.add_trace(trace)\n",
    "        \n",
    "# Make 10th trace visible\n",
    "fig.data[19].visible = True # (because we add two traces per plot we need to multiply by two and make both visible)\n",
    "fig.data[20].visible = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plot\n",
    "fig.update_layout(   \n",
    "    sliders=create_sliders_2traces(df_collection),\n",
    "    xaxis=dict(title='Component 1'),\n",
    "    yaxis=dict(title='Component 2'))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
